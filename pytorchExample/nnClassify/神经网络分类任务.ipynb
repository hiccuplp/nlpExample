{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist分类任务：\n",
    "\n",
    "- 网络基本构建与训练方法，常用函数解析\n",
    "\n",
    "- torch.nn.functional模块\n",
    "\n",
    "- nn.Module模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取Mnist数据集\n",
    "- 会自动进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "# PATH.mkdir(parents=True, exist_ok=True)：使用mkdir方法创建\"mnist\"子文件夹。parents=True表示如果需要创建的父文件夹不存在，则会一并创建；\n",
    "# exist_ok=True表示如果已存在的文件夹，不会报错并允许已存在的文件夹。\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "\n",
    "# 通过使用Path类来构建文件路径，将路径和文件名组合在一起，并使用as_posix()方法将路径转换为POSIX格式。\n",
    "# 接下来，使用gzip.open()函数打开gzip压缩文件，并指定打开模式为\"rb\"，表示以二进制模式读取文件。\n",
    "# 在打开的文件对象上，使用pickle.load()函数来加载保存在文件中的数据。encoding=\"latin-1\"参数表示使用latin-1编码来解析pickle数据。\n",
    "# 使用多重打包操作符((x_train, y_train), (x_valid, y_valid), _) =将解压后的数据分配给变量，其中(x_train, y_train)和(x_valid, y_valid)是两个元组，\n",
    "# 分别包含训练数据和验证数据的输入和标签。剩余的变量_表示不需要使用的值，可以忽略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784是mnist数据集每个样本的像素点个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(784,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)\n",
    "print(x_train[0].shape)\n",
    "\n",
    "# 使用imshow函数来显示图像。imshow函数的第一个参数是要显示的图像数据，它被重构成一个28x28的二维数组，使用reshape函数实现。cmap=\"gray\"参数指定使用灰度颜色映射。\n",
    "# 这段代码的效果是在屏幕上显示一个28x28像素的图像，该图像由x_train[0]中的数据重构而成。图像是使用灰度颜色值表示的，从黑色到白色共256个灰度等级。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/4.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/5.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意数据需转换成tensor才能参与后续建模训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "# map函数被用于将x_train、y_train、x_valid和y_valid四个变量转换为torch.tensor函数的参数。map函数的作用是对传入的序列中的每个元素应用指定的函数，\n",
    "# 并返回一个包含每个元素转换结果的迭代器。\n",
    "# 在这种情况下，map(torch.tensor, (x_train, y_train, x_valid, y_valid))将x_train、y_train、x_valid和y_valid四个变量依次传递给torch.tensor函数，\n",
    "# 并将其结果作为迭代器返回。这个迭代器包含了四个转换后的张量对象，可以用于后续的进一步处理或操作。\n",
    "print(type(x_train))\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional 很多层和函数在这里都会见到\n",
    "\n",
    "torch.nn.functional中有很多功能，后续会常用的。那什么时候使用nn.Module，什么时候使用nn.functional呢？一般情况下，如果模型有可学习的参数，最好用nn.Module，其他情况nn.functional相对更简单一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb.mm(weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.8578, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]\n",
    "weights = torch.randn([784, 10], dtype = torch.float,  requires_grad = True) \n",
    "bs = 64\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个model来更简化代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 必须继承nn.Module且在其构造函数中需调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.out  = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'Mnist_NN'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._get_name()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以打印我们定义好名字里的权重和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[-0.0086,  0.0285,  0.0234,  ...,  0.0322,  0.0270,  0.0137],\n",
      "        [-0.0142,  0.0217,  0.0071,  ...,  0.0321,  0.0066, -0.0199],\n",
      "        [ 0.0085,  0.0059,  0.0356,  ...,  0.0028,  0.0104,  0.0309],\n",
      "        ...,\n",
      "        [ 0.0156,  0.0023,  0.0260,  ...,  0.0107, -0.0262,  0.0189],\n",
      "        [-0.0072,  0.0102, -0.0279,  ...,  0.0108,  0.0278, -0.0350],\n",
      "        [-0.0337, -0.0200,  0.0301,  ...,  0.0269,  0.0293, -0.0004]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([ 0.0047,  0.0238, -0.0293, -0.0175,  0.0072, -0.0227, -0.0113, -0.0150,\n",
      "        -0.0210,  0.0164, -0.0117,  0.0247, -0.0141,  0.0338, -0.0306,  0.0311,\n",
      "         0.0005, -0.0191,  0.0097,  0.0034, -0.0015,  0.0207,  0.0260, -0.0152,\n",
      "         0.0320,  0.0341,  0.0173,  0.0013,  0.0195, -0.0204,  0.0083, -0.0328,\n",
      "        -0.0016, -0.0294,  0.0159, -0.0257, -0.0278,  0.0051,  0.0342, -0.0083,\n",
      "        -0.0039, -0.0056, -0.0250,  0.0126,  0.0067,  0.0333, -0.0089,  0.0099,\n",
      "        -0.0168, -0.0058, -0.0256, -0.0017,  0.0202, -0.0330, -0.0121,  0.0284,\n",
      "        -0.0196,  0.0197, -0.0284,  0.0299,  0.0205, -0.0245, -0.0052,  0.0237,\n",
      "         0.0083,  0.0238,  0.0285,  0.0147,  0.0072,  0.0228, -0.0279,  0.0172,\n",
      "         0.0216,  0.0092,  0.0260,  0.0230, -0.0026,  0.0286,  0.0303, -0.0294,\n",
      "         0.0186,  0.0093,  0.0272, -0.0273,  0.0055,  0.0293, -0.0328, -0.0191,\n",
      "        -0.0087, -0.0142,  0.0351,  0.0070,  0.0141,  0.0334, -0.0308, -0.0234,\n",
      "         0.0097,  0.0048,  0.0089, -0.0184,  0.0288,  0.0009, -0.0167, -0.0114,\n",
      "         0.0355,  0.0275,  0.0044, -0.0291, -0.0240,  0.0038, -0.0222, -0.0292,\n",
      "         0.0138, -0.0036,  0.0294, -0.0320,  0.0150,  0.0172,  0.0262,  0.0256,\n",
      "         0.0130,  0.0323, -0.0279,  0.0286, -0.0044, -0.0295, -0.0152, -0.0045],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[ 0.0262,  0.0449, -0.0030,  ...,  0.0062,  0.0593,  0.0759],\n",
      "        [ 0.0864,  0.0125, -0.0249,  ...,  0.0394,  0.0624,  0.0536],\n",
      "        [ 0.0351, -0.0627, -0.0143,  ...,  0.0557,  0.0753, -0.0454],\n",
      "        ...,\n",
      "        [-0.0291,  0.0672,  0.0196,  ...,  0.0578,  0.0604, -0.0080],\n",
      "        [-0.0362, -0.0249,  0.0617,  ...,  0.0428, -0.0610, -0.0618],\n",
      "        [ 0.0175,  0.0589, -0.0098,  ..., -0.0751, -0.0048, -0.0628]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([-0.0519,  0.0768,  0.0236,  0.0822, -0.0803,  0.0710,  0.0589,  0.0438,\n",
      "        -0.0601, -0.0634, -0.0825, -0.0375,  0.0792,  0.0824,  0.0239,  0.0426,\n",
      "         0.0246,  0.0429,  0.0542, -0.0830,  0.0734, -0.0857,  0.0860,  0.0309,\n",
      "         0.0522, -0.0380, -0.0163,  0.0269,  0.0862, -0.0091, -0.0142, -0.0184,\n",
      "        -0.0602, -0.0355,  0.0530, -0.0451,  0.0870,  0.0091,  0.0445, -0.0163,\n",
      "        -0.0634, -0.0804,  0.0823, -0.0078, -0.0808,  0.0016,  0.0209, -0.0225,\n",
      "         0.0563, -0.0187,  0.0419, -0.0013,  0.0270, -0.0784,  0.0636,  0.0752,\n",
      "         0.0471,  0.0167, -0.0856,  0.0050, -0.0238,  0.0820,  0.0343,  0.0504,\n",
      "        -0.0200,  0.0775, -0.0616, -0.0816,  0.0619,  0.0712, -0.0111,  0.0555,\n",
      "        -0.0420,  0.0233, -0.0710, -0.0802, -0.0367,  0.0543, -0.0202, -0.0407,\n",
      "         0.0602,  0.0468,  0.0786, -0.0092,  0.0801, -0.0870,  0.0755,  0.0495,\n",
      "        -0.0272,  0.0513, -0.0471, -0.0178, -0.0130,  0.0496, -0.0534, -0.0194,\n",
      "         0.0616, -0.0186, -0.0169, -0.0784, -0.0729,  0.0065, -0.0122,  0.0180,\n",
      "         0.0774,  0.0326,  0.0403,  0.0641, -0.0036,  0.0713,  0.0581,  0.0332,\n",
      "         0.0143,  0.0730,  0.0414,  0.0582,  0.0311,  0.0553, -0.0112, -0.0173,\n",
      "        -0.0319, -0.0806, -0.0582, -0.0209,  0.0446, -0.0023, -0.0167, -0.0330,\n",
      "        -0.0834, -0.0383,  0.0044,  0.0066,  0.0529,  0.0569, -0.0103, -0.0147,\n",
      "        -0.0534,  0.0815,  0.0271, -0.0381,  0.0744,  0.0404,  0.0635, -0.0647,\n",
      "        -0.0330, -0.0542, -0.0344, -0.0753,  0.0447,  0.0193,  0.0556, -0.0876,\n",
      "         0.0871, -0.0771, -0.0571, -0.0144, -0.0037,  0.0392, -0.0007,  0.0351,\n",
      "         0.0673,  0.0670, -0.0626,  0.0270,  0.0763,  0.0001, -0.0078,  0.0618,\n",
      "         0.0360, -0.0729, -0.0675, -0.0663,  0.0053, -0.0079,  0.0228,  0.0333,\n",
      "         0.0103,  0.0385,  0.0111, -0.0217,  0.0328, -0.0390, -0.0827,  0.0310,\n",
      "        -0.0554,  0.0465,  0.0167,  0.0036, -0.0468, -0.0814,  0.0281, -0.0287,\n",
      "         0.0712,  0.0491, -0.0155, -0.0181, -0.0281, -0.0046,  0.0827,  0.0091,\n",
      "        -0.0190, -0.0841,  0.0300, -0.0208, -0.0626, -0.0587, -0.0396,  0.0115,\n",
      "         0.0617, -0.0086, -0.0466, -0.0675, -0.0344, -0.0022,  0.0274,  0.0543,\n",
      "        -0.0131, -0.0662, -0.0140,  0.0699,  0.0306,  0.0617, -0.0391, -0.0621,\n",
      "         0.0821,  0.0387,  0.0536, -0.0783, -0.0831,  0.0371, -0.0677,  0.0099,\n",
      "         0.0833,  0.0697, -0.0172,  0.0844, -0.0160, -0.0551, -0.0277, -0.0346,\n",
      "        -0.0202,  0.0002, -0.0341,  0.0431, -0.0703, -0.0603, -0.0374, -0.0802,\n",
      "        -0.0283,  0.0085,  0.0032,  0.0800, -0.0575,  0.0622,  0.0730, -0.0129],\n",
      "       requires_grad=True) torch.Size([256])\n",
      "out.weight Parameter containing:\n",
      "tensor([[-0.0312, -0.0014, -0.0121,  ..., -0.0576, -0.0522, -0.0024],\n",
      "        [-0.0184, -0.0318,  0.0310,  ..., -0.0428, -0.0620, -0.0547],\n",
      "        [ 0.0580, -0.0401, -0.0323,  ..., -0.0280,  0.0318, -0.0511],\n",
      "        ...,\n",
      "        [ 0.0478,  0.0096,  0.0331,  ..., -0.0588,  0.0130,  0.0289],\n",
      "        [ 0.0072,  0.0422, -0.0474,  ..., -0.0059,  0.0613, -0.0099],\n",
      "        [-0.0158, -0.0343, -0.0043,  ...,  0.0614,  0.0439, -0.0451]],\n",
      "       requires_grad=True) torch.Size([10, 256])\n",
      "out.bias Parameter containing:\n",
      "tensor([-0.0458, -0.0124, -0.0586, -0.0456,  0.0341, -0.0030,  0.0016,  0.0523,\n",
      "        -0.0550, -0.0014], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter, parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用TensorDataset和DataLoader来简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dl))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般在训练模型时加上model.train()，这样会正常使用Batch Normalization和 Dropout\n",
    "- 测试的时候一般选择model.eval()，这样就不会使用Batch Normalization和 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        # 后面需要在验证集上面进行计算loss，同时不想让这个计算中计算梯度对后面的训练产生影响\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "    return model, optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三行搞定！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前step:0 验证集损失：2.279128847503662\n",
      "当前step:1 验证集损失：2.2494867935180665\n",
      "当前step:2 验证集损失：2.2040577396392824\n",
      "当前step:3 验证集损失：2.129009489822388\n",
      "当前step:4 验证集损失：2.0034153610229493\n",
      "当前step:5 验证集损失：1.805879399871826\n",
      "当前step:6 验证集损失：1.5462325132369996\n",
      "当前step:7 验证集损失：1.2857624677658082\n",
      "当前step:8 验证集损失：1.0738435333251952\n",
      "当前step:9 验证集损失：0.914775092792511\n",
      "当前step:10 验证集损失：0.7968136585235596\n",
      "当前step:11 验证集损失：0.7076095352172852\n",
      "当前step:12 验证集损失：0.64020578956604\n",
      "当前step:13 验证集损失：0.5882641596794128\n",
      "当前step:14 验证集损失：0.548335736656189\n",
      "当前step:15 验证集损失：0.515262677192688\n",
      "当前step:16 验证集损失：0.48860035152435305\n",
      "当前step:17 验证集损失：0.46697572021484374\n",
      "当前step:18 验证集损失：0.4488448283672333\n",
      "当前step:19 验证集损失：0.43313484816551207\n",
      "当前step:20 验证集损失：0.4198346958875656\n",
      "当前step:21 验证集损失：0.40867107026576993\n",
      "当前step:22 验证集损失：0.3981704381942749\n",
      "当前step:23 验证集损失：0.3894855699539185\n",
      "当前step:24 验证集损失：0.38122034640312197\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(25, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}